% vim: tw=110:fo=an1lt

\chapter{Related works}

This chapter examines several popular existing protocols and general characteristics of their implementations.
For each protocol, we briefly describe its history, outline its features and mode of operation, and weigh its
strong and weak points, with some emphasis on security.

Unless noted otherwise, the protocols described here run on top of TCP/IP.

\section{FTP}

FTP, the File Transfer Protocol, is one of the oldest network protocols for file transfer, and probably the
oldest that is still widely used. It was first introduced in~1973 as RFC~454~\cite{rfc454} and the most recent
accepted standard is RFC~959~\cite{rfc959} from~1985. Several proposed extensions were published after that,
mostly describing how the standard has evolved in practical use.

With FTP, the client establishes a text-based, line-oriented {\it control} connection to the server. Through this
the user can configure session parameters, traverse and list directories and manipulate directory entries,
similar to an interactive shell. Commands are designed for human use first, e.g., the HELP command, or the
LIST command that lists contents of the current directory in a platform-dependent textual format. Results of
directory listing, as well as actual file transfers, run on separate {\it data} connections, which are
negotiated on the control connection. This can be used to arrange a file transfer between two servers, without
the data going through the client. It also means that in order to support FTP transparently, firewalls and
NATs must run deep packet inspection on FTP traffic.

Many of the protocol's features are designed to enable interoperation between systems with wildly different
concepts of file and directory structure. FTP supports several kinds of files depending on how the host system
stores them, several transfer modes, and explicit control of text file transfer, such as pagination and print
character conversion. These features are largely useless in the relatively homogenous computing environments
of today. On the other hand, while the protocol has distinct ASCII and EBCDIC modes, it has no support for
internationalized encodings.

FTP does not support transfer interleaving and one control connection can only support one data transfer at
a time. Furthermore, there is no support for ranged reads and writes.  It is possible to seek to a specified
point in a file before performing a data transfer, and it is possible to stop the transfer at an arbitrary
point, but this must be done in real time, and a new connection must be opened for each data transfer.  This
makes FTP particularly unsuitable for filesystem-like operation.

Users authenticate themselves with user name, password and optionally an account name. The protocol specifies
no encryption, so all information is transfered in plain text. RFC~4217~\cite{rfc4217} specifies a variant of
FTP that uses TLS for encryption. However, this makes FTP traffic opaque, so special care must be taken when
firewalls or NATs are involved.

\section{HTTP}

Mentioned mostly for completeness, HTTP (Hyper-Text Transfer Protocol) is at its core a protocol for
retrieving files from remote servers. Although it has limited capabilities for creating, updating and deleting
content, those are usually used in application-specific manner and not for general file manipulation. It
doesn't support directory manipulation at all. Current HTTP specification is described by
RFC~2616~\cite{rfc2616} from~1999.

HTTP is text-based. Each client request specifies a method (one of {\tt GET}, {\tt PUT}, {\tt POST} or {\tt
DELETE}) and an URL on the first line, followed by any number of headers, one per line.  Headers can specify
range of transfer, content metadata, instructions for proxies, client expectations etc. The headers section
can be followed by a body containing arbitrary data. Similarly, server response starts with a numeric response
code, followed by headers and data payload.

The protocol is fully stateless and has no concept of sessions beyond single request/response exchanges,
although it allows reusing a single TCP connection as an optimization. Heavy emphasis is placed on
cacheability of requests, and due to this property, it is simple to build load balancers and content delivery
networks for HTTP servers. Although less common today, proxy servers can be placed on LANs as transparent
local caches for clients retrieving the same data.

HTTP specification allows a simplistic authentication model based on username/password combinations.
RFC~2069~\cite{rfc2069} improves upon this model by introducing digest-based authentication.
RFC~2818~\cite{rfc2818} describes how to use the protocol with TLS, which is commonly known as HTTPS.

\subsection{WebDAV}

WebDAV (Web Distributed Authoring and Versioning) protocol is an extension of HTTP, designed to provide the
World-Wide Web network with standardized authoring capabilities. It was first specified in~1999 as
RFC~2518~\cite{rfc2518}, with RFC~4918~\cite{rfc4918} from 2007 being the latest published specification.
As~of~2013, WebDAV and its extensions are actively maintained by a number of IETF working groups.

WebDAV specifies several new methods that add directory manipulation and locking functionality, as well as
corresponding headers and XML-based formats of data payloads. It also specifies detailed semantics for file
and directory operations. Despite its name, versioning is not part of WebDAV's core functionality -- it is
specified as an extension \cite{rfc3253}.

WebDAV does not modify the way HTTP operates, so it is still stateless with no session support. It uses HTTP's
authentication models and it can run under HTTPS encryption mode. It is also backwards-compatible with
HTTP-only proxies. Depending on the nature of the proxy, WebDAV traffic can either pass through unchanged, or
a failure is detected and doesn't endanger consistency of server state.

The protocol's features work well for filesystem-like access, and indeed, WebDAV is often supported out of the
box in modern operating systems. However, these implementation tend to be slightly incompatible esp. in terms
of user authentication and authorship management.

\section{SMB}

Server Message Block is an evolution of a proprietary networking protocol designed at IBM around the year
1985. Originally using NetBIOS API to abstract away the transport layer, its current version usually runs
directly on TCP/IP.  The most recent version is SMB 3.0, which first appeared in 2012 with Windows 8 and is
actively maintained by Microsoft. It is specified in~\cite{mssmb2} as part of Microsoft's Open Specifications
initiative.

SMB was originally designed as an all-encompasing networking protocol for small local networks. Apart from
publishing parts of directory trees, it allows sharing printers, ports and even some IPC mechanisms. The
NetBIOS API allows service discovery, but these days this capability is mostly superseded by use of
Dynamic~DNS.

SMB is a binary protocol and its file transfer capabilities are designed for filesystem-like access. It
provides locking mechanisms and transparent failover features. Since SMB 2.0, GSS-API is used for user
authentication.  Support for digitally-signed communications existed in older versions of the protocol, and
version 3.0 enhances that with full encryption support.

As a filesystem, SMB is feature-complete and has good performance characteristics. The drawback is that due to
the complexity, it not so well suited for simpler file transfer tasks, and it is difficult to implement as
a separate protocol outside its environment.

\section{NFS}

Originally called Sun Network Filesystem, NFS was introduced in a paper~\cite{nfs85} in 1985. It was later
standardized as Network File System version 2 in RFC~1094~\cite{rfc1094}, and version 3 was released in 1995
as RFC~1813~\cite{rfc1813}. NFS can run over UDP and version 3 adds support for TCP transport layer. The
protocol itself is fully stateless, in order to improve concurrency and provide cleaner failure recovery.

NFS protocol is a neat example of modularity and technology reuse. It is defined in terms of
Sun~RPC~\cite{rfc1057} calls, the format of which is in turn specified in the XDR~\cite{rfc1832}
language.\footnote{The final on-the-wire format is binary.} The core protocol only deals with filesystem
operations, and the specification describes related protocols that provide lock management and stateful
filesystem mounting procedures. Although not formally specified in the protocol, implementations usually
contain a replay cache module~\cite{juszczak89} that reduces server load and shields the stateless server from
the non-idempotent replay problem. NFS relies on Sun~RPC security mechanisms for authentication, and version
3 does not support encryption.

NFS version 3 is now superseded by version 4. Its specification documents are still relevant, however, as they
provide great insight into file transfer protocol design and challenges.

\subsection{NFSv4}

Version 4 of the Network File System protocol was introduced in December 2000. The most up-to-date
specification is RFC~5661~\cite{rfc5661} from 2010, describing version~4.1. Version 4.2 is in active
development.

NFSv4 is the first version of NFS developed by the Internet Engineering Task Force, after Sun Microsystems
ceded formal control of the specification to the Internet Society~\cite{rfc2339}. It brings major changes to
the protocol, introducing stateful operation and mandating strong security. Other areas of improvement include
performance, esp. on high-latency networks and the Internet, internationalization, interoperability with
non-POSIX operating systems, etc. Version 4.1 introduces Parallel NFS extension and other features designed to
support server clusters.

All the new features significantly increase complexity of the protocol -- for a rough measure, with over 600
pages, RFC~5661 is more than five times longer than the version 3 specification. This is obviously not
a problem in itself, but it does mean that understanding, implementing and maintaining correctness of NFSv4
software is a much more difficult task. Also, similar to SMB, the complexity makes it less suitable for
simpler file transfer tasks.

\section{SFTP}

SSH File Transfer Protocol, or SFTP, started out as a proprietary extension to the SSH~2.0~\cite{rfc4251}
protocol suite around the year 1997. The first standard draft was introduced in 2001, and standardization
attempts continued unsuccessfully for several years. Development was stopped and the working group closed
in~2006~\cite{secsh-email}. The most recent draft specificaton is from July 2006~\cite{draft-secsh-13}.
Despite the fact that SFTP is not a recognized Internet standard, it is widely implemented in SSH-related
software.

SFTP is a binary protocol with a clearly modern design. It has a small core feature set of filesystem-like
operations, but also includes support for extended attributes, ACLs, and byte-range locks.  The protocol
design allows for both stateful and stateless server implementations, but there is no form of replay
protection. Some consideration is given to cross-platform interoperability, but on the whole, the
functionality remains largely POSIX-centric.

Provisions for authentication and encryption are not part of the protocol, SFTP fully relies on the SSH
transport layer to provide these features.
